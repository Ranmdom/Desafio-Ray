# Desafio T√©cnico - Pipeline ETL + Dashboard de F1 Highlights 2024

Este projeto implementa um **pipeline ETL completo** e um **dashboard interativo** para analisar os v√≠deos de highlights da temporada 2024 da F√≥rmula¬†1:

1. **ETL Pipeline (`pipeline.py`)**

   * Extrai v√≠deos de uma playlist do YouTube (API v3).
   * Filtra apenas publica√ß√µes de 2024.
   * Enriquecimento: coleta estat√≠sticas (views, likes, coment√°rios).
   * Carrega (upsert) em tabela `f1_highlights` no Supabase/Postgres.

2. **Dashboard Interativo (`dashboard.py`)**

   * Consome dados da tabela `f1_highlights`.
   * Apresenta KPIs e gr√°ficos (Streamlit + Altair + Plotly).
   * Filtros: data (calend√°rio) e circuitos.

---

## 1. Pipeline ETL (pipeline.py)

### üìã Descri√ß√£o

O script `pipeline.py`:

* Configura log (N√≠vel INFO).
* Carrega vari√°veis de ambiente `YOUTUBE_API_KEY` e `SUPABASE_DB_URL`.
* Extrai IDs de v√≠deos da playlist via `playlistItems.list()`, filtrando por `publishedAt` entre 2024-01-01 e 2024-12-31.
* Obt√©m detalhes com `videos.list()` em batches de 50 IDs: `snippet` + `statistics`.
* Constr√≥i DataFrame Pandas com colunas:

  * `videoId`, `title`, `publishedAt`, `viewCount`, `likeCount`, `commentCount`.
* Upsert em Postgres:

  * Cria tabela `f1_highlights` se n√£o existir.
  * `INSERT ... ON CONFLICT (videoId) DO UPDATE` para manter dados atualizados.

### üöÄ Pr√©-requisitos

* Python 3.8+
* Conta no Google Cloud com YouTube Data API v3 habilitada
* Vari√°veis de ambiente:

  ```dotenv
  YOUTUBE_API_KEY="SUA_API_KEY"
  SUPABASE_DB_URL="postgresql://user:senha@host:porta/database"
  YOUTUBE_PLAYLIST_ID="ID_DA_PLAYLIST"  # opcional, default √© playlist oficial F1
  ```

### ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o

```bash
git clone https://github.com/SEU_USUARIO/f1-pipeline-dashboard.git
cd f1-pipeline-dashboard
python -m venv venv
source venv/bin/activate      # Linux/macOS
venv\\Scripts\\activate     # Windows
pip install -r requirements.txt
python pipeline.py
```

> Ao final, a tabela `f1_highlights` estar√° atualizada no seu banco.

### üõ†Ô∏è Detalhes T√©cnicos

* **Logging**: `logging.basicConfig` com timestamps e n√≠veis.
* **Pagination**: loop at√© esgotar `nextPageToken`.
* **SQLAlchemy**: executa comandos DDL e DML com `engine.begin()`.

---

## 2. Dashboard Streamlit (dashboard.py)

### üìã Descri√ß√£o

O `dashboard.py` consome `f1_highlights` e gera:

* **Vis√£o R√°pida**: total de v√≠deos, views, likes, coment√°rios e taxa de likes.
* **Top 5 Highlights**: gr√°fico de barras horizontais.
* **Evolu√ß√£o Mensal de Views**: linha temporal.
* **Engajamento vs Views**: scatter plot.
* **Crescimento de Engajamento**: gr√°fico de √°rea mensal.
* **Filtros**: sele√ß√£o de per√≠odo via calend√°rio e filtro por circuitos.

### üöÄ Pr√©-requisitos

* **Mesmas vari√°veis** do pipeline (usa `SUPABASE_DB_URL`).
* Instalar depend√™ncias:

  ```bash
  pip install streamlit pandas sqlalchemy altair plotly python-dotenv
  ```

### ‚ñ∂Ô∏è Execu√ß√£o

```bash
streamlit run dashboard.py
```

Abra `http://localhost:8501`.

---

## 3. Como isso atende ao Desafio

* **API Consumption**: pipeline via YouTube Data API.
* **Data Manipulation**: Pandas + SQLAlchemy para aggregations e upsert.
* **Visualization**: Streamlit com gr√°ficos interativos e filtros.

---

## 4. Testes e Deploy

* **Smoke Tests**: scripts em `tests/` validam pipeline e dashboard.
* **Deploy**: Streamlit Cloud, Heroku ou Render configurado para rodar `pipeline.py` (cron) e `dashboard.py`.

---

## ü§ù Contribui√ß√µes

Fork, crie branches e abra PRs!

---

## üìÑ Licen√ßa

MIT
